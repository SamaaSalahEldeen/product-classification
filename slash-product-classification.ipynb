{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7820811,"sourceType":"datasetVersion","datasetId":4582175}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install tensorflow","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-12T04:25:27.807487Z","iopub.execute_input":"2024-03-12T04:25:27.807847Z","iopub.status.idle":"2024-03-12T04:25:44.224923Z","shell.execute_reply.started":"2024-03-12T04:25:27.807816Z","shell.execute_reply":"2024-03-12T04:25:44.223824Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.51.1)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\nCollecting keras<2.16,>=2.15.0 (from tensorflow)\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\nDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 3.0.5\n    Uninstalling keras-3.0.5:\n      Successfully uninstalled keras-3.0.5\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.15.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"\nfrom keras import preprocessing\nimport os\nimport numpy as np\nimport pandas as pd\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom keras.utils import to_categorical\nfrom scipy import ndimage\nfrom keras import models\nfrom keras import layers\nfrom keras.models import load_model\nfrom keras.models import save_model\nimport keras.backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout\nimport tensorflow as tf\nfrom keras.preprocessing import image\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-03-12T04:25:44.227028Z","iopub.execute_input":"2024-03-12T04:25:44.227326Z","iopub.status.idle":"2024-03-12T04:25:58.171370Z","shell.execute_reply.started":"2024-03-12T04:25:44.227299Z","shell.execute_reply":"2024-03-12T04:25:58.170430Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-03-12 04:25:46.366698: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-12 04:25:46.366824: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-12 04:25:46.536170: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# Function to preprocess the dataset\ndef preprocess_dataset(data):\n    data_resized = cv2.resize(data, (224, 224))    # resize\n    data_normalized = data_resized / 255.0         # normalize\n    return data_normalized\n\n# Function to preprocess the test dataset\ndef preprocess_test_dataset(test_dataset_path):\n    preprocessed_data = np.empty((0, 224, 224, 3), dtype=np.float32)  # To store preprocessed images\n    labels = []              # To store labels\n\n    test_images_paths = [os.path.join(test_dataset_path, filename) for filename in os.listdir(test_dataset_path) if\n                         filename.endswith(('.jpg', '.jpeg', '.png'))]   # Get paths of all images in the test dataset directory\n\n    for image_path in test_images_paths:\n        image = cv2.imread(image_path)\n        if image is None:\n            print(f\"Error: Unable to read the image: {image_path}\")\n            continue\n\n        # Preprocess the image\n        preprocessed_image = preprocess_dataset(image)\n        preprocessed_data = np.concatenate((preprocessed_data, preprocessed_image[None]), axis=0)\n\n        # Extract folder name as the label\n        label = os.path.basename(os.path.dirname(image_path))\n        labels.append(label)\n\n    # Convert the preprocessed data to a numpy array\n    preprocessed_data = np.array(preprocessed_data)\n\n    return preprocessed_data, labels\n\n# the train and validation datasets\npath = \"/kaggle/input/products2/dataset/train\"\n\ndef Train_data_preprocessing_(path):\n    image_generator = ImageDataGenerator(\n        rescale=1/255,\n        rotation_range=10,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        validation_split=0.2\n    )\n\n    train_dataset = image_generator.flow_from_directory(\n        batch_size=32,\n        directory=path,\n        shuffle=True,\n        target_size=(224, 224),\n        subset=\"training\",\n        class_mode='categorical'\n    )\n\n    test_dataset = image_generator.flow_from_directory(\n        batch_size=32,\n        directory=path,\n        shuffle=True,\n        target_size=(224, 224),\n        subset=\"validation\",\n        class_mode='categorical'\n    )\n\n    return train_dataset, test_dataset\n\ntrain, test = Train_data_preprocessing_(path)","metadata":{"execution":{"iopub.status.busy":"2024-03-12T04:28:21.964376Z","iopub.execute_input":"2024-03-12T04:28:21.965074Z","iopub.status.idle":"2024-03-12T04:28:22.000174Z","shell.execute_reply.started":"2024-03-12T04:28:21.965040Z","shell.execute_reply":"2024-03-12T04:28:21.999334Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Found 37 images belonging to 5 classes.\nFound 7 images belonging to 5 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(5, activation='softmax'))\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nhistory = model.fit(\n    train,\n    epochs=10,\n    validation_data=test\n)\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\nmodel_checkpoint = ModelCheckpoint('best_model2.h5', save_best_only=True)\n\n# Training\nmodel.fit(train, epochs=50, validation_data=test, callbacks=[early_stopping, model_checkpoint], verbose=1)\n\nmodel.save('model3.h5')","metadata":{"execution":{"iopub.status.busy":"2024-03-12T04:28:26.983594Z","iopub.execute_input":"2024-03-12T04:28:26.984543Z","iopub.status.idle":"2024-03-12T04:29:05.675280Z","shell.execute_reply.started":"2024-03-12T04:28:26.984512Z","shell.execute_reply":"2024-03-12T04:29:05.674194Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1710217713.773057     138 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"2/2 [==============================] - 9s 1s/step - loss: 1.7960 - accuracy: 0.2162 - val_loss: 5.7735 - val_accuracy: 0.2857\nEpoch 2/10\n2/2 [==============================] - 1s 750ms/step - loss: 3.6356 - accuracy: 0.3243 - val_loss: 1.9204 - val_accuracy: 0.2857\nEpoch 3/10\n2/2 [==============================] - 1s 236ms/step - loss: 1.9259 - accuracy: 0.1892 - val_loss: 1.6178 - val_accuracy: 0.1429\nEpoch 4/10\n2/2 [==============================] - 1s 756ms/step - loss: 1.6091 - accuracy: 0.1892 - val_loss: 1.6096 - val_accuracy: 0.1429\nEpoch 5/10\n2/2 [==============================] - 1s 751ms/step - loss: 1.6066 - accuracy: 0.2432 - val_loss: 1.5795 - val_accuracy: 0.2857\nEpoch 6/10\n2/2 [==============================] - 1s 203ms/step - loss: 1.5690 - accuracy: 0.2973 - val_loss: 1.5252 - val_accuracy: 0.2857\nEpoch 7/10\n2/2 [==============================] - 1s 196ms/step - loss: 1.4935 - accuracy: 0.3243 - val_loss: 1.4865 - val_accuracy: 0.5714\nEpoch 8/10\n2/2 [==============================] - 1s 703ms/step - loss: 1.5125 - accuracy: 0.4054 - val_loss: 1.6493 - val_accuracy: 0.4286\nEpoch 9/10\n2/2 [==============================] - 1s 735ms/step - loss: 1.4170 - accuracy: 0.4054 - val_loss: 1.4161 - val_accuracy: 0.5714\nEpoch 10/10\n2/2 [==============================] - 1s 741ms/step - loss: 1.2290 - accuracy: 0.5676 - val_loss: 1.3465 - val_accuracy: 0.4286\nEpoch 1/50\n2/2 [==============================] - ETA: 0s - loss: 1.3051 - accuracy: 0.4595","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"},{"name":"stdout","text":"2/2 [==============================] - 2s 1s/step - loss: 1.3051 - accuracy: 0.4595 - val_loss: 1.3159 - val_accuracy: 0.4286\nEpoch 2/50\n2/2 [==============================] - 1s 200ms/step - loss: 1.2478 - accuracy: 0.4595 - val_loss: 1.3234 - val_accuracy: 0.2857\nEpoch 3/50\n2/2 [==============================] - 2s 1s/step - loss: 1.2299 - accuracy: 0.4595 - val_loss: 1.2392 - val_accuracy: 0.5714\nEpoch 4/50\n2/2 [==============================] - 1s 773ms/step - loss: 1.1804 - accuracy: 0.5135 - val_loss: 1.2624 - val_accuracy: 0.4286\nEpoch 5/50\n2/2 [==============================] - 2s 2s/step - loss: 1.1679 - accuracy: 0.5135 - val_loss: 1.1862 - val_accuracy: 0.4286\nEpoch 6/50\n2/2 [==============================] - 2s 1s/step - loss: 1.1016 - accuracy: 0.4595 - val_loss: 1.1789 - val_accuracy: 0.2857\nEpoch 7/50\n2/2 [==============================] - 1s 201ms/step - loss: 1.1143 - accuracy: 0.4865 - val_loss: 1.2482 - val_accuracy: 0.5714\nEpoch 8/50\n2/2 [==============================] - 1s 755ms/step - loss: 1.0938 - accuracy: 0.5405 - val_loss: 1.2312 - val_accuracy: 0.4286\nEpoch 9/50\n2/2 [==============================] - 3s 3s/step - loss: 1.0534 - accuracy: 0.6216 - val_loss: 1.1644 - val_accuracy: 0.5714\nEpoch 10/50\n2/2 [==============================] - 1s 775ms/step - loss: 1.0553 - accuracy: 0.5946 - val_loss: 1.2390 - val_accuracy: 0.4286\nEpoch 11/50\n2/2 [==============================] - 2s 2s/step - loss: 0.9806 - accuracy: 0.6216 - val_loss: 0.9211 - val_accuracy: 0.5714\nEpoch 12/50\n2/2 [==============================] - 1s 222ms/step - loss: 0.9054 - accuracy: 0.6216 - val_loss: 1.2405 - val_accuracy: 0.2857\nEpoch 13/50\n2/2 [==============================] - 1s 747ms/step - loss: 0.8600 - accuracy: 0.6486 - val_loss: 1.2697 - val_accuracy: 0.4286\nEpoch 14/50\n2/2 [==============================] - 1s 954ms/step - loss: 0.9074 - accuracy: 0.6216 - val_loss: 1.3314 - val_accuracy: 0.2857\n","output_type":"stream"}]},{"cell_type":"code","source":"# Path to the test dataset\ntest_dataset_path = \"/kaggle/input/products2/dataset/test\"\n\ndef test_images(test_dataset_path, model):\n    preprocessed_data, labels = preprocess_test_dataset(test_dataset_path)\n\n    if preprocessed_data.shape[0] == 0:\n        print(\"No valid images in the test dataset.\")\n        return\n\n    # Make predictions\n    predictions = model.predict(preprocessed_data)\n    predicted_labels = np.argmax(predictions, axis=1)\n\n    results = pd.DataFrame({'image_id': labels, 'predicted_folder': predicted_labels})\n    print(results)\n\n    #csv_file_path = 'predicted_folders333.csv'\n    #results.to_csv(csv_file_path, index=False)\n\n# Load the model\nmodel2 = load_model('model3.h5')\n\n# Set the path to the test dataset\ntest_dataset_path = \"/kaggle/input/products2/dataset/test\"\n\n# Call the test_images function\ntest_images(test_dataset_path, model2)","metadata":{"execution":{"iopub.status.busy":"2024-03-12T04:35:04.797491Z","iopub.execute_input":"2024-03-12T04:35:04.798000Z","iopub.status.idle":"2024-03-12T04:35:06.560115Z","shell.execute_reply.started":"2024-03-12T04:35:04.797965Z","shell.execute_reply":"2024-03-12T04:35:06.559060Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 82ms/step\n   image_id  predicted_folder\n0      test                 2\n1      test                 4\n2      test                 1\n3      test                 1\n4      test                 1\n5      test                 1\n6      test                 4\n7      test                 1\n8      test                 4\n9      test                 1\n10     test                 1\n11     test                 2\n12     test                 1\n13     test                 2\n","output_type":"stream"}]}]}